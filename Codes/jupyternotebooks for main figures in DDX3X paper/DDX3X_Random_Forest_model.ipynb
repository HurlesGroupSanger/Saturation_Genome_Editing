{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5a8e7d-6dfa-4ee7-ad64-2102151990a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pysam\n",
    "from liftover import get_lifter\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.cluster import KMeans\n",
    "import tabix\n",
    "import myvariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2f1b84-e6f7-499c-9268-7a1adead8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary of LFC (using counts per million normalisation etc) by uniq-ID\n",
    "\n",
    "LFC_by_uniq={}\n",
    "with open('/nfs/users/nfs_e/er10/SGE/data/Release_4/HK_new_method_LFC_R4.txt', 'r') as f:\n",
    "    header=f.readline().strip().split('\\t')\n",
    "    uniq_col=header.index('uniq_key')\n",
    "    D7_LFC_col=header.index('combined_LFC_d7')\n",
    "    D11_LFC_col=header.index('combined_LFC_d11')\n",
    "    D15_LFC_col=header.index('combined_LFC_d15')\n",
    "    D21_LFC_col=header.index('combined_LFC_d21')\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        fields=line.strip().split('\\t')\n",
    "        uniq=fields[uniq_col].strip('\"\"')\n",
    "        D7_LFC = fields[D7_LFC_col].strip('\"\"')\n",
    "        D11_LFC = fields[D11_LFC_col].strip('\"\"')\n",
    "        D15_LFC = fields[D15_LFC_col].strip('\"\"')\n",
    "        D21_LFC = fields[D21_LFC_col].strip('\"\"')\n",
    "        LFC_by_uniq[uniq]=[D7_LFC, D11_LFC, D15_LFC, D21_LFC]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00bd12f0-1379-4682-a0fc-bf4b907a3eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Variant_category', 'D15LFC_GMM_C1z', 'D15LFC_GMM_C2z', 'D15LFC_GMM_cut_0.99', 'D15LFC_GMM_cut_0.9', 'D7_combined_LFC', 'D11_combined_LFC', 'D15_combined_LFC', 'D21_combined_LFC', 'DeltaDeltaG', 'protein_cons', 'recurrent_clinical_vars', 'ML_category', 'My_clusters_C1z_90', 'Time_cluster', 'C1z_90_gmm_p0', 'C1z_90_gmm_p1', 'SpliceAI_delta_score', 'Primary_consequence', 'revel', 'inverse_sift', 'numeric_polyphen', 'Cut_0.9', 'Cut_0.8', 'Cut_0.7', 'Cut_0.6', 'redundancy', 'counts_NF_U_F', 'Clinical_source', 'Clinical_ID', 'inheritance', 'pathogenicity', 'sex', 'pop_db', 'UKBB_male_female_count', 'UKKBB_AC', 'UKBB_AN', 'UKBB_AF', 'UKBB_AP', 'Gnomad_maf', 'Gnomad_AC', '\"\"', 'X', 'uniq_key', 'Old_name', 'Seq', 'New_name', 'old_region', 'chrom', 'VCF_position', 'VCF_Ref', 'VCF_Alt', 'PAM_codon', 'species', 'assembly', 'gene_id', 'transcript_id', 'ref_chr', 'ref_strand', 'ref_start', 'ref_end', 'revc', 'ref_seq', 'pam_seq', 'vcf_alias', 'vcf_var_id', 'mut_position', 'ref', 'new', 'ref_aa', 'alt_aa', 'mut_type', 'mutator', 'oligo_length', 'mseq', 'Location', 'Allele', 'Consequence', 'IMPACT', 'SYMBOL', 'Gene', 'Feature_type', 'Feature', 'BIOTYPE', 'EXON', 'INTRON', 'HGVSc', 'HGVSp', 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', 'Existing_variation', 'DISTANCE', 'STRAND', 'FLAGS', 'SYMBOL_SOURCE', 'HGNC_ID', 'CANONICAL', 'MANE_SELECT', 'MANE_PLUS_CLINICAL', 'TSL', 'APPRIS', 'CCDS', 'ENSP', 'SWISSPROT', 'TREMBL', 'UNIPARC', 'UNIPROT_ISOFORM', 'SIFT', 'PolyPhen', 'DOMAINS', 'HGVS_OFFSET', 'AF', 'gnomAD_AF', 'gnomAD_AFR_AF', 'gnomAD_AMR_AF', 'gnomAD_ASJ_AF', 'gnomAD_EAS_AF', 'gnomAD_FIN_AF', 'gnomAD_NFE_AF', 'gnomAD_OTH_AF', 'gnomAD_SAS_AF', 'CLIN_SIG', 'SOMATIC', 'PHENO', 'PUBMED', 'MOTIF_NAME', 'MOTIF_POS', 'HIGH_INF_POS', 'MOTIF_SCORE_CHANGE', 'TRANSCRIPTION_FACTORS', 'Condel', 'DisGeNET_PMID', 'DisGeNET_SCORE', 'DisGeNET_disease', 'MaxEntScan_alt', 'MaxEntScan_diff', 'MaxEntScan_ref', 'ada_score', 'rf_score', 'SpliceAI_pred_DP_AG', 'SpliceAI_pred_DP_AL', 'SpliceAI_pred_DP_DG', 'SpliceAI_pred_DP_DL', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL', 'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL', 'SpliceAI_pred_SYMBOL', 'LoFtool', 'CADD_PHRED', 'CADD_RAW', 'BLOSUM62', 'PHENOTYPES', 'SGE_exon_group', 'ref_codon', 'alt_codon', 'sg1_sg2_combined_annotation', 'sg1_sg2_combined_annotation_count', 'Variant_duplication', 'Variant_Sources.x', 'PAM_status', 'sg1_err', 'sg2_err', 'sg1_rate', 'sg2_rate', 'sg1_raw_rate', 'sg2_raw_rate', 'sg1_baseMean', 'sg2_baseMean', 'weight1', 'weight2', 'sum_of_weigth', 'SE_bind', 'weighted_sg1rate', 'weighted_sg2rate', 'sum_of_weighed_rate', 'combined_rate', 'combined_Z', 'two_tailed_p', 'BH_FDR', 'C1_z', 'C2_z', 'Cluster', 'uncertainty', 'Variant_Sources.y', 'HK_pathogenicity']\n"
     ]
    }
   ],
   "source": [
    "''' ML_category is as follows:\n",
    "- clinical benign/likely benign variants and variant seen in GnomAD or UKBB = 0\n",
    "- denovo, pathogenic/clinical pathogenic variants from ClinVar and DECIPHER + denovo variants from Kaplanis/Samocha et al (where not VUS in Decipher), and GEL = 1'''\n",
    "\n",
    "data_X=[]\n",
    "data_y=[]\n",
    "with open('/nfs/users/nfs_e/er10/SGE/SGE_paper/Sup_Info//Supp_Table_5.txt', 'r')as f:\n",
    "    header=f.readline().strip().split('\\t')\n",
    "    #print(header)\n",
    "    uniq_col=header.index('SGE_oligo_name')\n",
    "    MLcat_col=header.index('Category_for_RF')\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        ML_cat=fields[MLcat_col].strip()\n",
    "        uniq=fields[uniq_col].strip('\"\"')\n",
    "        D7_LFC, D11_LFC, D15_LFC, D21_LFC = LFC_by_uniq[uniq]\n",
    "        if ML_cat != 'NA':\n",
    "            X=[uniq, ML_cat, D7_LFC, D11_LFC, D15_LFC, D21_LFC]\n",
    "            data_X.append(X)\n",
    "            data_y.append(int(ML_cat))\n",
    "\n",
    "all_data_X=np.array(data_X)\n",
    "all_data_y=np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a762177f-7c65-4e2e-bba7-c238d7705a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: TN=432, TP=134, Testing set: TN=108, TP=34 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stratified sampling of test and train datasets to ensure that the representation of positive and negative variants is equal in each\n",
    "\n",
    "# split into train/test sets with same class ratio\n",
    "trainX, testX, trainy, testy = train_test_split(all_data_X, all_data_y, test_size=0.2, random_state=2, stratify=data_y)\n",
    "# summarize\n",
    "train_0, train_1 = len(trainy[trainy==0]), len(trainy[trainy==1])\n",
    "test_0, test_1 = len(testy[testy==0]), len(testy[testy==1])\n",
    "print('Training set: TN=%d, TP=%d, Testing set: TN=%d, TP=%d' % (train_0, train_1, test_0, test_1), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d45ee150-20ae-4d28-9f3a-f909f0901ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test and train datasets to file\n",
    "\n",
    "with open('/nfs/users/nfs_e/er10/SGE/data/Release_4/MachineLearning/ML_input_test_train_data_D7D11D15.txt', 'w')as out:\n",
    "    out_header='\\t'.join(['test/train', 'uniq_ID', 'ML_cat', 'D7_LFC', 'D11_LFC', 'D15_LFC', 'D21_LFC'])+'\\n'\n",
    "    out.write(out_header)\n",
    "    for item in trainX:\n",
    "        uniq, ML_cat, D7_LFC, D11_LFC, D15_LFC, D21_LFC = item\n",
    "        out_line='\\t'.join(['train', uniq, ML_cat, D7_LFC, D11_LFC, D15_LFC, D21_LFC])+'\\n'\n",
    "        out.write(out_line)\n",
    "    for item in testX:\n",
    "        uniq, ML_cat, D7_LFC, D11_LFC, D15_LFC, D21_LFC = item\n",
    "        out_line='\\t'.join(['test', uniq, ML_cat, D7_LFC, D11_LFC, D15_LFC, D21_LFC])+'\\n'\n",
    "        out.write(out_line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec3ff2e5-de40-4c53-b6e1-228533c127d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/train', 'uniq_ID', 'ML_cat', 'D7_LFC', 'D11_LFC', 'D15_LFC', 'D21_LFC']\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the different models\n",
    "\n",
    "D15_LFCs=[]\n",
    "uniq_IDs=[]\n",
    "testy=[]\n",
    "trainy=[]\n",
    "model1_testX=[]\n",
    "model1_trainX=[]\n",
    "model2_testX=[]\n",
    "model2_trainX=[]\n",
    "model3_testX=[]\n",
    "model3_trainX=[]\n",
    "model4_testX=[]\n",
    "model4_trainX=[]\n",
    "model5_testX=[]\n",
    "model5_trainX=[]\n",
    "model6_testX=[]\n",
    "model6_trainX=[]\n",
    "model7_testX=[]\n",
    "model7_trainX=[]\n",
    "model8_testX=[]\n",
    "model8_trainX=[]\n",
    "\n",
    "\n",
    "with open('/nfs/users/nfs_e/er10/SGE/data/Release_4/MachineLearning/ML_input_test_train_data_D7D11D15.txt', 'r')as f:\n",
    "    header=f.readline().strip().split('\\t')\n",
    "    print(header)\n",
    "    ID_col=header.index('uniq_ID')\n",
    "    test_train_col=header.index('test/train')\n",
    "    ML_cat_col=header.index('ML_cat')\n",
    "    D7_LFC_col=header.index('D7_LFC')\n",
    "    D11_LFC_col=header.index('D11_LFC')\n",
    "    D15_LFC_col=header.index('D15_LFC')\n",
    "    D21_LFC_col=header.index('D21_LFC')\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        fields=line.strip().split('\\t')\n",
    "        uniq=fields[ID_col].strip()\n",
    "        test_train = fields[test_train_col].strip()\n",
    "        ML_cat=fields[ML_cat_col].strip()\n",
    "        D7_LFC=float(fields[D7_LFC_col].strip())\n",
    "        D11_LFC=float(fields[D11_LFC_col].strip())\n",
    "        D15_LFC=float(fields[D15_LFC_col].strip())\n",
    "        D21_LFC=float(fields[D21_LFC_col].strip())\n",
    "        if test_train=='test':\n",
    "            testy.append([int(ML_cat), uniq])\n",
    "            model1_testX.append([D7_LFC,D11_LFC,D15_LFC])\n",
    "            model2_testX.append([D7_LFC])\n",
    "            model3_testX.append([D11_LFC])\n",
    "            model4_testX.append([D15_LFC])\n",
    "            model5_testX.append([D7_LFC,D11_LFC])\n",
    "            model6_testX.append([D7_LFC, D15_LFC])\n",
    "            model7_testX.append([D11_LFC, D15_LFC])\n",
    "            model8_testX.append([D7_LFC, D11_LFC, D15_LFC, D21_LFC])\n",
    "        elif test_train =='train':\n",
    "            trainy.append(int(ML_cat))\n",
    "            model1_trainX.append([D7_LFC,D11_LFC,D15_LFC])\n",
    "            model2_trainX.append([D7_LFC])\n",
    "            model3_trainX.append([D11_LFC])\n",
    "            model4_trainX.append([D15_LFC])\n",
    "            model5_trainX.append([D7_LFC,D11_LFC])\n",
    "            model6_trainX.append([D7_LFC, D15_LFC])\n",
    "            model7_trainX.append([D11_LFC, D15_LFC])\n",
    "            model8_trainX.append([D7_LFC, D11_LFC, D15_LFC, D21_LFC])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a11d75d2-8f2b-46b6-94ac-b3e377aa9b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      "true positives 33\n",
      "true negatives 108\n",
      "false positives 0\n",
      "false negatives 1\n",
      "sensitivity 0.9705882352941176 specificity 1.0 PPV 1.0 NPV 0.9908256880733946 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''ML Models\n",
    "1. D7_LFC,D11_LFC,D15_LFC\n",
    "2. D7_LFC\n",
    "3. D11_LFC\n",
    "4. D15_LFC\n",
    "5. D7_LFC,D11_LFC\n",
    "6. D7_LFC, D15_LFC\n",
    "7. D11_LFC, D15_LFC\n",
    "8. D7_LFC, D11_LFC, D15_LFC, D21_LFC\n",
    "\n",
    "Compare with using GMM posterior-probability cut_offs\n",
    "'''\n",
    "\n",
    "training_sets=[[model1_trainX, model1_testX], [model2_trainX, model2_testX], [model3_trainX, model3_testX], [model4_trainX, model4_testX], [model5_trainX, model5_testX], [model6_trainX, model6_testX], [model7_trainX, model7_testX], [model8_trainX, model8_testX]]\n",
    "\n",
    "counter=1\n",
    "for pair in training_sets:\n",
    "    trainX, testX = pair\n",
    "    TP, TN, FP, FN=(0,0,0,0)\n",
    "    model = RandomForestClassifier()\n",
    "    model = model.fit(trainX, trainy)\n",
    "    print('model', counter)\n",
    "    counter = counter+1\n",
    "\n",
    "    x=0\n",
    "    while x<len(testX):\n",
    "        for row in testX:\n",
    "            pred = model.predict([row])\n",
    "            # GnomAD variants:\n",
    "            if testy[x]==0:\n",
    "                # This variant is a true negative, calculate the TN and FP rate using the model's prediction\n",
    "                if pred[0]==0:\n",
    "                    TN=TN+1\n",
    "                elif pred[0]==1:\n",
    "                    #print('false positive', row)\n",
    "                    FP=FP+1\n",
    "\n",
    "            # clinical variants\n",
    "            elif testy[x]==1:\n",
    "                if pred[0] == 1:\n",
    "                    TP=TP+1\n",
    "                elif pred[0] ==0:\n",
    "                    #print('false negative', row)\n",
    "                    FN=FN+1\n",
    "\n",
    "            x=x+1\n",
    "\n",
    "    '''Sensitivity = TP/TP+FN, PPV = TP/TP+FP, Specificity = TN/TN+FP, NPV = TN/(FN+TN)'''\n",
    "\n",
    "    sens=TP/(TP+FN)\n",
    "    spec=TN/(TN+FP)\n",
    "    PPV=TP/(TP+FP)\n",
    "    NPV=TN/(TN+FN)\n",
    "    print('true positives', TP)\n",
    "    print('true negatives', TN)\n",
    "    print('false positives', FP)\n",
    "    print('false negatives', FN)\n",
    "    print('sensitivity', sens, 'specificity', spec, 'PPV', PPV, 'NPV', NPV, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8959856-9ff8-430c-8de4-b0035f25d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply model to the rest of the data and predict classification for each variant:\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model = model.fit(model1_trainX, trainy)\n",
    "\n",
    "with open('/nfs/users/nfs_e/er10/SGE/data/Release_4/MachineLearning/ML_output_R4_4_all_training_vars.txt', 'w') as out:\n",
    "    out_header='\\t'.join(['Uniq_ID', 'LFCD7', 'LFCD11', 'LFCD15','ML_category', 'prob_functional', 'prob_non_functional'])+'\\n'\n",
    "    out.write(out_header)\n",
    "    for uniqID in LFC_by_uniq:\n",
    "        LFCd7, LFCd11, LFCd15, LFCd21= LFC_by_uniq[uniqID]\n",
    "        LFCd7=float(LFCd7)\n",
    "        LFCd11=float(LFCd11)\n",
    "        LFCd15=float(LFCd15)\n",
    "        model_input = [[LFCd7, LFCd11, LFCd15]]\n",
    "        yhat = model.predict(model_input)\n",
    "        predicted_class = yhat[0]\n",
    "        probs = model.predict_proba(model_input)\n",
    "        for item in probs:\n",
    "            prob_F = item[0]\n",
    "            prob_NF = item[1]\n",
    "        out_line = '\\t'.join([uniqID, str(LFCd7), str(LFCd11), str(LFCd15), str(predicted_class), str(prob_F), str(prob_NF)])+'\\n'\n",
    "        out.write(out_line)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
